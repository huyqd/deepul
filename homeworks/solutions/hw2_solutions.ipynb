{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mg6ittKNrEtv"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rll/deepul/blob/master/homeworks/solutions/hw2_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rdy1FtrRpGcC"
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "## Overview\n",
    "This semester, all homeworks will be conducted through Google Colab notebooks. All code for the homework assignment will be written and run in this notebook. Running in Colab will automatically provide a GPU, but you may also run this notebook locally by following [these instructions](https://research.google.com/colaboratory/local-runtimes.html) if you wish to use your own GPU.\n",
    "\n",
    "You will save images in the notebooks to use and fill out a given LaTeX template which will be submitted to Gradescope, along with your notebook code.\n",
    "\n",
    "## Using Colab\n",
    "On the left-hand side, you can click the different icons to see a Table of Contents of the assignment, as well as local files accessible through the notebook.\n",
    "\n",
    "Make sure to go to **Runtime -> Change runtime type** and select **GPU** as the hardware accelerator. This allows you to use a GPU. Run the cells below to get started on the assignment. Note that a session is open for a maximum of 12 hours, and using too much GPU compute may result in restricted access for a short period of time. Please start the homework early so you have ample time to work.\n",
    "\n",
    "**If you loaded this notebook from clicking \"Open in Colab\" from github, you will need to save it to your own Google Drive to keep your work.**\n",
    "\n",
    "## General Tips\n",
    "In each homework problem, you will implement an flow model and run it on one to two datasets. We provide the expected outputs to help as a sanity check.\n",
    "\n",
    "Feel free to print whatever output (e.g. debugging code, training code, etc) you want, as the graded submission will be the submitted pdf with images.\n",
    "\n",
    "After you complete the assignment, download all of the image outputted in the results/ folder and upload them to the figure folder in the given latex template.\n",
    "\n",
    "Run the cells below to download and load up the starter code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "wUVy2glDtoaR",
    "outputId": "1f7104a8-5d26-44a6-da3f-4d71e247dfd9"
   },
   "outputs": [],
   "source": [
    "# !if [ -d deepul ]; then rm -Rf deepul; fi\n",
    "# !git clone https://github.com/rll/deepul.git\n",
    "# !pip install ./deepul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHWosWrbpO5Y"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from deepul.hw2_helper import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7E4CMktzo100"
   },
   "source": [
    "# Question 1: 2D Data\n",
    "\n",
    "In this question, we will train two variants of flow models on continuous 2D data. \n",
    "\n",
    "Execute the cell below to visualize our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "colab_type": "code",
    "id": "ehhv2FZGo4_b",
    "outputId": "1cfaf43c-32cf-47b5-ff0d-b1f451fe3d0e"
   },
   "outputs": [],
   "source": [
    "visualize_q1_data(dset_type=1)\n",
    "visualize_q1_data(dset_type=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kSGTVznZqAR3"
   },
   "source": [
    "## Part (a) Autoregressive Flow [15pt]\n",
    "\n",
    "In an autoregressive flow, we learn the transformation $z_i = f(x_i ; x_{1:i-1})$. The log-likelihood is then $\\log p_\\theta(x) = \\sum_{i=1}^d p(z_i) + log |\\frac{dz_i}{dx_i}|$ because the Jacobian is triangular. For each dimension, use the CDF of a mixture of Gaussians or Logistics to map to the latent space, which should be $z_i \\sim \\text{Unif}[0, 1]$ i.i.d..\n",
    "\n",
    "Fit $p_\\theta$ with maximum likelihood via stochastic gradient descent on the training set. Since this is a 2D problem, you can either learn $z_0 = f(x_0)$ and $z_1 = f(x_1; x_0)$ together with a MADE model, or with separate networks. Use your favorite version of stochastic gradient descent, and optimize your hyperparameters on a validation set of your choice.\n",
    "\n",
    "**You will provide these deliverables**\n",
    "\n",
    "\n",
    "1.   Over the course of training, record the average negative log-likelihood (nats / dim) of the training data (per minibatch) and test data (for your entire test set). Code is provided that automatically plots the training curves. \n",
    "2.   Report the final test set performance of your final model\n",
    "3. Show a heatmap of the densities learned by your model\n",
    "4. Show what the training set looks like when mapped to the latent space. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yg0Jmo1PSaE4"
   },
   "source": [
    "### Solution\n",
    "Fill out the function below and return the necessary arguments. Feel free to create more cells if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wEuQ0V-uEOI1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm_notebook, trange\n",
    "\n",
    "import deepul.pytorch_util as ptu\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for x in train_loader:\n",
    "        x = x.to(ptu.device).float().contiguous()\n",
    "        loss = model.nll(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "\n",
    "def eval_loss(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x in data_loader:\n",
    "            x = x.to(ptu.device).float().contiguous()\n",
    "            loss = model.nll(x)\n",
    "            total_loss += loss * x.shape[0]\n",
    "        avg_loss = total_loss / len(data_loader.dataset)\n",
    "    return avg_loss.item()\n",
    "\n",
    "\n",
    "def train_epochs(model, train_loader, test_loader, train_args):\n",
    "    epochs, lr = train_args[\"epochs\"], train_args[\"lr\"]\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    test_loss = eval_loss(model, test_loader)\n",
    "    test_losses.append(test_loss)  # loss at init\n",
    "    for epoch in tqdm_notebook(range(epochs), desc=\"Epoch\", leave=False):\n",
    "        model.train()\n",
    "        epoch_train_losses = train(model, train_loader, optimizer)\n",
    "        train_losses.extend(epoch_train_losses)\n",
    "\n",
    "        test_loss = eval_loss(model, test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6f56foklEIl-"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "\n",
    "ptu.set_gpu_mode(False)\n",
    "\n",
    "\n",
    "class MixtureCDFFlow(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_dist=\"uniform\",\n",
    "        mixture_dist=\"gaussian\",\n",
    "        n_components=4,\n",
    "        plot_bounds=(-3, 3),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.composition = False\n",
    "        if base_dist == \"uniform\":\n",
    "            self.base_dist = Uniform(0.0, 1.0)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.loc = nn.Parameter(torch.randn(n_components), requires_grad=True)\n",
    "        self.log_scale = nn.Parameter(torch.zeros(n_components), requires_grad=True)\n",
    "        self.weight_logits = nn.Parameter(torch.zeros(n_components), requires_grad=True)\n",
    "        if mixture_dist == \"gaussian\":\n",
    "            self.mixture_dist = Normal\n",
    "        elif mixture_dist == \"logistic\":\n",
    "            raise NotImplementedError\n",
    "        self.n_components = n_components\n",
    "        self.plot_bounds = plot_bounds\n",
    "\n",
    "    def flow(self, x):\n",
    "        # z = cdf of x\n",
    "        weights = (\n",
    "            F.softmax(self.weight_logits, dim=0).unsqueeze(0).repeat(x.shape[0], 1)\n",
    "        )\n",
    "        z = (\n",
    "            self.mixture_dist(self.loc, self.log_scale.exp()).cdf(\n",
    "                x.unsqueeze(1).repeat(1, self.n_components)\n",
    "            )\n",
    "            * weights\n",
    "        ).sum(dim=1)\n",
    "        z = torch.clamp(z, 0, 1 - 1e-5)\n",
    "\n",
    "        # log_det = log dz/dx = log pdf(x)\n",
    "        log_det = (\n",
    "            (\n",
    "                self.mixture_dist(self.loc, self.log_scale.exp())\n",
    "                .log_prob(x.unsqueeze(1).repeat(1, self.n_components))\n",
    "                .exp()\n",
    "                * weights\n",
    "            )\n",
    "            .sum(dim=1)\n",
    "            .log()\n",
    "        )\n",
    "\n",
    "        return z, log_det\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        z, log_det = self.flow(x)\n",
    "        return self.base_dist.log_prob(z) + log_det\n",
    "\n",
    "    # Compute loss as negative log-likelihood\n",
    "    def nll(self, x):\n",
    "        return -self.log_prob(x).mean()\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_hidden):\n",
    "            layers.append(nn.Linear(input_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class AutoregressiveFlow(nn.Module):\n",
    "    \"\"\"\n",
    "    Assumes that we're modeling a 2D distribution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim1_mixture_dist=\"gaussian\",\n",
    "        dim1_n_components=5,\n",
    "        dim2_mixture_dist=\"gaussian\",\n",
    "        dim2_n_components=5,\n",
    "        mlp_hidden_size=64,\n",
    "        mlp_n_layers=3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim1_flow = MixtureCDFFlow(\n",
    "            mixture_dist=dim1_mixture_dist, n_components=dim1_n_components\n",
    "        ).to(ptu.device)\n",
    "        self.mlp = MLP(1, mlp_n_layers, mlp_hidden_size, dim2_n_components * 3).to(\n",
    "            ptu.device\n",
    "        )\n",
    "        self.dim2_n_components = dim2_n_components\n",
    "        self.base_dist = Uniform(ptu.tensor(0.0), ptu.tensor(1.0))\n",
    "        if dim2_mixture_dist == \"gaussian\":\n",
    "            self.mixture_dist = Normal\n",
    "        elif dim2_mixture_dist == \"logistic\":\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def flow(self, x):\n",
    "        # individually flow on each dim\n",
    "        x1, x2 = torch.chunk(x, 2, dim=1)\n",
    "        # dim 1\n",
    "        z1, log_det1 = self.dim1_flow.flow(x1.squeeze())\n",
    "\n",
    "        # dim1\n",
    "        loc, log_scale, weight_logits = torch.chunk(self.mlp(x1), 3, dim=1)\n",
    "        weights = F.softmax(weight_logits, dim=1)\n",
    "        z2 = (\n",
    "            self.mixture_dist(loc, log_scale.exp()).cdf(\n",
    "                x2.repeat(1, self.dim2_n_components)\n",
    "            )\n",
    "            * weights\n",
    "        ).sum(dim=1)\n",
    "\n",
    "        z2 = torch.clamp(z2, 0, 1 - 1e-5)\n",
    "        log_det2 = (\n",
    "            (\n",
    "                self.mixture_dist(loc, log_scale.exp())\n",
    "                .log_prob(x2.repeat(1, self.dim2_n_components))\n",
    "                .exp()\n",
    "                * weights\n",
    "            )\n",
    "            .sum(dim=1)\n",
    "            .log()\n",
    "        )\n",
    "        return torch.cat([z1.unsqueeze(1), z2.unsqueeze(1)], dim=1), torch.cat(\n",
    "            [log_det1.unsqueeze(1), log_det2.unsqueeze(1)], dim=1\n",
    "        )\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        z, log_det = self.flow(x)\n",
    "        return (self.base_dist.log_prob(z) + log_det).mean(\n",
    "            dim=1\n",
    "        )  # shape: [batch_size, dim]\n",
    "\n",
    "    def nll(self, x):\n",
    "        return -self.log_prob(x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJNa6dHKpEQU"
   },
   "outputs": [],
   "source": [
    "def q1_a(train_data, test_data, dset_id):\n",
    "    \"\"\"\n",
    "    train_data: An (n_train, 2) numpy array of floats in R^2\n",
    "    test_data: An (n_test, 2) numpy array of floats in R^2\n",
    "    dset_id: An identifying number of which dataset is given (1 or 2). Most likely\n",
    "               used to set different hyperparameters for different datasets, or\n",
    "               for plotting a different region of densities\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train_losses evaluated every minibatch\n",
    "    - a (# of epochs + 1,) numpy array of test_losses evaluated once at initialization and after each epoch\n",
    "    - a numpy array of size (?,) of probabilities with values in [0, +infinity).\n",
    "        Refer to the commented hint.\n",
    "    - a numpy array of size (n_train, 2) of floats in [0,1]^2. This represents\n",
    "        mapping the train set data points through our flow to the latent space.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    # create data loaders\n",
    "    loader_args = dict(batch_size=128, shuffle=True)\n",
    "    train_loader = data.DataLoader(train_data, **loader_args)\n",
    "    test_loader = data.DataLoader(test_data, **loader_args)\n",
    "\n",
    "    # model\n",
    "    ar_flow = AutoregressiveFlow()\n",
    "\n",
    "    # train\n",
    "    train_losses, test_losses = train_epochs(\n",
    "        ar_flow, train_loader, test_loader, dict(epochs=100, lr=5e-3)\n",
    "    )\n",
    "\n",
    "    # heatmap\n",
    "    dx, dy = 0.025, 0.025\n",
    "    if dset_id == 1:  # face\n",
    "        x_lim = (-4, 4)\n",
    "        y_lim = (-4, 4)\n",
    "    elif dset_id == 2:  # two moons\n",
    "        x_lim = (-1.5, 2.5)\n",
    "        y_lim = (-1, 1.5)\n",
    "    y, x = np.mgrid[\n",
    "        slice(y_lim[0], y_lim[1] + dy, dy), slice(x_lim[0], x_lim[1] + dx, dx)\n",
    "    ]\n",
    "    mesh_xs = ptu.FloatTensor(np.stack([x, y], axis=2).reshape(-1, 2))\n",
    "    densities = np.exp(ptu.get_numpy(ar_flow.log_prob(mesh_xs)))\n",
    "\n",
    "    # latents\n",
    "    z, _ = ar_flow.flow(ptu.FloatTensor(train_data))\n",
    "    latents = ptu.get_numpy(z)\n",
    "\n",
    "    return train_losses, test_losses, densities, latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SiGBSP-ESeIj"
   },
   "source": [
    "### Results\n",
    "\n",
    "Once you've implemented `q1_a`, execute the cells below to visualize and save your results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_save_results(1, \"a\", q1_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874,
     "referenced_widgets": [
      "82e1d23df2c34fc98d1b9a276ee435db",
      "04b5e9c4be5841139ddfcb10a7b0d4d5",
      "4305a379952c403c831aa80a7277a8c2",
      "64dd75b1a2bf4b329dae8ded5705fcde",
      "72da61b014334c63b49e1704ccb447ab",
      "2ff11b35ae2445d48f3eb9f38e98d2de",
      "14e9adb89a4241a59b73969994ba8287",
      "2b5760ae26d546fe995e5adce3adfac8"
     ]
    },
    "colab_type": "code",
    "id": "sJVOUEaaZXcA",
    "outputId": "a5c3880a-53c8-4419-de3b-eb5f9b2f6968"
   },
   "outputs": [],
   "source": [
    "q1_save_results(2, \"a\", q1_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DiyFXlj0rfcr"
   },
   "source": [
    "## Part (b) RealNVP [15pt]\n",
    "In this part, we want to train a flow with the following structure: \n",
    "$(z_1, z_2) = (f_{\\theta, 1} \\circ \\cdots \\circ f_{\\theta, n})$, \n",
    "where each $f_{\\theta, i}$ is an affine transformation of 1 dimension, conditioned on the other. According to [Density Estimation Using Real NVP](https://arxiv.org/abs/1605.08803) Section 4.1, there's a particularly good way to parameterize the affine transformation:\n",
    "\n",
    "Assuming that we're conditioning on $x_1$ and transforming $x_2$, we have \n",
    "\n",
    "- $z_1 = x_1$\n",
    "\n",
    "- $ \\text{log_scale} = \\text{scale} \\times tanh(g_{\\theta, \\text{scale}}(x_1)) + \\text{scale_shift}$\n",
    "\n",
    "- $z_2 = exp(\\text{log_scale}) \\times x_2 + g_{\\theta, \\text{shift}}(x_1)$\n",
    "\n",
    "where $g_\\theta$, $\\text{scale}$, and $\\text{scale_shift}$ are all learned parameters. The latent space should be $z \\sim \\mathcal N (0, I_2)$.\n",
    "\n",
    "**Train a RealNVP model and provide the same set of corresponding deliverables as part (a)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4dnQIg_TDx6"
   },
   "source": [
    "### Solution\n",
    "Fill out the function below and return the necessary arguments. Feel free to create more cells if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s357UOHZcyBr"
   },
   "outputs": [],
   "source": [
    "class AffineTransform(nn.Module):\n",
    "    def __init__(self, type, n_hidden=2, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.mask = self.build_mask(type=type)\n",
    "        self.scale = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        self.scale_shift = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        self.mlp = MLP(\n",
    "            input_size=2, n_hidden=n_hidden, hidden_size=hidden_size, output_size=2\n",
    "        )\n",
    "\n",
    "    def build_mask(self, type):\n",
    "        # if type == \"left\", left half is a one\n",
    "        # if type == right\", right half is a one\n",
    "        assert type in {\"left\", \"right\"}\n",
    "        if type == \"left\":\n",
    "            mask = ptu.FloatTensor([1.0, 0.0])\n",
    "        elif type == \"right\":\n",
    "            mask = ptu.FloatTensor([0.0, 1.0])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        # returns transform(x), log_det\n",
    "        batch_size = x.shape[0]\n",
    "        mask = self.mask.repeat(batch_size, 1)\n",
    "        x_ = x * mask\n",
    "\n",
    "        log_s, t = self.mlp(x_).split(1, dim=1)  # todo: fix\n",
    "        log_s = self.scale * torch.tanh(log_s) + self.scale_shift\n",
    "        t = t * (1.0 - mask)\n",
    "        log_s = log_s * (1.0 - mask)\n",
    "\n",
    "        if reverse:  # inverting the transformation\n",
    "            x = (x - t) * torch.exp(-log_s)\n",
    "        else:\n",
    "            x = x * torch.exp(log_s) + t\n",
    "        return x, log_s\n",
    "\n",
    "\n",
    "class SigmoidFlow(nn.Module):\n",
    "    def forward(self, x, reverse=False):\n",
    "        if reverse:\n",
    "            z = -torch.log(torch.reciprocal(x) - 1)\n",
    "        else:\n",
    "            z = torch.sigmoid(x)\n",
    "        return z, z.log() + (1 - z).log()\n",
    "\n",
    "\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, transforms):\n",
    "        super().__init__()\n",
    "\n",
    "        self.prior = torch.distributions.Normal(\n",
    "            torch.tensor(0.0).to(ptu.device), torch.tensor(1.0).to(ptu.device)\n",
    "        )\n",
    "        self.transforms = nn.ModuleList(transforms)\n",
    "\n",
    "    def flow(self, x):\n",
    "        # maps x -> z, and returns the log determinant (not reduced)\n",
    "        z, log_det = x, torch.zeros_like(x)\n",
    "        for op in self.transforms:\n",
    "            z, delta_log_det = op.forward(z)\n",
    "            log_det += delta_log_det\n",
    "        return z, log_det\n",
    "\n",
    "    def invert_flow(self, z):\n",
    "        # z -> x (inverse of f)\n",
    "        for op in reversed(self.transforms):\n",
    "            z, _ = op.forward(z, reverse=True)\n",
    "        return z\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        z, log_det = self.flow(x)\n",
    "        return torch.sum(log_det, dim=1) + torch.sum(self.prior.log_prob(z), dim=1)\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        z = self.prior.sample([num_samples, 2])\n",
    "        return self.invert_flow(z)\n",
    "\n",
    "    def nll(self, x):\n",
    "        return -self.log_prob(x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAvMQDJJrjNo"
   },
   "outputs": [],
   "source": [
    "def q1_b(train_data, test_data, dset_id):\n",
    "    \"\"\"\n",
    "    train_data: An (n_train, 2) numpy array of floats in R^2\n",
    "    test_data: An (n_test, 2) numpy array of floats in R^2\n",
    "    dset_id: An identifying number of which dataset is given (1 or 2). Most likely\n",
    "               used to set different hyperparameters for different datasets, or\n",
    "               for plotting a different region of densities\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train_losses evaluated every minibatch\n",
    "    - a (# of epochs + 1,) numpy array of test_losses evaluated once at initialization and after each epoch\n",
    "    - a numpy array of size (?,) of probabilities with values in [0, +infinity).\n",
    "        Refer to the commented hint.\n",
    "    - a numpy array of size (n_train, 2) of floats in R^2. This represents\n",
    "        mapping the train set data points through our flow to the latent space.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    # create data loaders\n",
    "    loader_args = dict(batch_size=128, shuffle=True)\n",
    "    train_loader = data.DataLoader(train_data, **loader_args)\n",
    "    test_loader = data.DataLoader(test_data, **loader_args)\n",
    "\n",
    "    # model\n",
    "    real_nvp = RealNVP(\n",
    "        [\n",
    "            AffineTransform(\"left\", n_hidden=2, hidden_size=64),\n",
    "            AffineTransform(\"right\", n_hidden=2, hidden_size=64),\n",
    "            AffineTransform(\"left\", n_hidden=2, hidden_size=64),\n",
    "            AffineTransform(\"right\", n_hidden=2, hidden_size=64),\n",
    "            AffineTransform(\"left\", n_hidden=2, hidden_size=64),\n",
    "            AffineTransform(\"right\", n_hidden=2, hidden_size=64),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # train\n",
    "    train_losses, test_losses = train_epochs(\n",
    "        real_nvp, train_loader, test_loader, dict(epochs=250, lr=5e-3)\n",
    "    )\n",
    "\n",
    "    # heatmap\n",
    "    dx, dy = 0.025, 0.025\n",
    "    if dset_id == 1:  # face\n",
    "        x_lim = (-4, 4)\n",
    "        y_lim = (-4, 4)\n",
    "    elif dset_id == 2:  # two moons\n",
    "        x_lim = (-1.5, 2.5)\n",
    "        y_lim = (-1, 1.5)\n",
    "    y, x = np.mgrid[\n",
    "        slice(y_lim[0], y_lim[1] + dy, dy), slice(x_lim[0], x_lim[1] + dx, dx)\n",
    "    ]\n",
    "    mesh_xs = ptu.FloatTensor(np.stack([x, y], axis=2).reshape(-1, 2))\n",
    "    densities = np.exp(ptu.get_numpy(real_nvp.log_prob(mesh_xs)))\n",
    "\n",
    "    # latents\n",
    "    z, _ = real_nvp.flow(ptu.FloatTensor(train_data))\n",
    "    latents = ptu.get_numpy(z)\n",
    "\n",
    "    return train_losses, test_losses, densities, latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VwZyhlewTHH4"
   },
   "source": [
    "### Results\n",
    "\n",
    "Once you've implemented `q1_b`, execute the cells below to visualize and save your results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874,
     "referenced_widgets": [
      "698eb0108e154b799b0bc85f12215c54",
      "e43bfafcb08344a89b3c4bbc1e4c1045",
      "8d83151bc7c540e1824cfaf1079c2649",
      "15f9f7bea21447a587cbe113bd8f1db8",
      "4a5f8210c0314f6a924f3fbb1f816a47",
      "26279b5b00d249d08db193c5d458d788",
      "925588a883d24a239f2dce621f3c3474",
      "af99978dfe194c5cabc7a22566a73f32"
     ]
    },
    "colab_type": "code",
    "id": "wnnQORaG6Ouf",
    "outputId": "6e080d9e-3717-497e-bc31-4bac813d00fa"
   },
   "outputs": [],
   "source": [
    "q1_save_results(1, \"b\", q1_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874,
     "referenced_widgets": [
      "e1dc0632bd95445a8944cd76afb3f668",
      "47fe7daee7eb41ec82d490f989ab916d",
      "6bbfc6f0221b4216ba7b79e84d330f1e",
      "4f47243631654ab8b874f69b70581f14",
      "7f8e58fa58b74581a4131dadcef8848f",
      "529698ae7efc4f099d9909f4d3f37a79",
      "b07b523f96de451fb7dc582b43dadef6",
      "11be4368f59f4d279ccd6c7e1c3fb975"
     ]
    },
    "colab_type": "code",
    "id": "1jLGoDa46RM6",
    "outputId": "3bc7ce22-1c90-4614-dffc-3e9df0f2724b"
   },
   "outputs": [],
   "source": [
    "q1_save_results(2, \"b\", q1_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bk6l6G30tEIg"
   },
   "source": [
    "# Question 2: Autoregressive Flows for Images [20pt]\n",
    "We can scale up the autoregressive flows from 1(a) to high-dimensional image data. In this question, we will focus on the black-and-white shapes dataset from Homework 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "alF9C1t-tEys",
    "outputId": "711abbb6-fcfc-4f2c-fa51-72600d6b3eb4"
   },
   "outputs": [],
   "source": [
    "visualize_q2_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sDywq5JZR4Eg"
   },
   "source": [
    "Adapt your PixelCNN implementation from Homework 1 and use it as an autoregressive flow model on the black-and-white shapes dataset. Using the base architecture from Homework 1 3(a), output a mixture of logistics or gaussians (instead of logits), whose CDF we will use as our flow for each dimension of x. \n",
    "\n",
    "Remember: you must dequantize the data and scale it between 0 and 1 for the autoregressive flow to have stable training. \n",
    "\n",
    "**You will provide these deliverables**\n",
    "\n",
    "1.   Over the course of training, record the average negative log-likelihood (nats / dim) of the training data (per minibatch) and test data (for your entire test set). Code is provided that automatically plots the training curves. **Make sure to account for any rescaling you do in your nats/dim.**\n",
    "2.   Report the final test set performance of your final model\n",
    "3. 100 samples from your autoregressive flow. Our plotting code will show your samples, with and without clipping and flooring (to remove the quantization). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHHxHqSJTSAa"
   },
   "source": [
    "### Solution\n",
    "Fill out the function below and return the necessary arguments. Feel free to create more cells if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bY4RgrSseJZp"
   },
   "outputs": [],
   "source": [
    "def train_with_dequantization_q2(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for x in train_loader:\n",
    "        x = x.to(ptu.device).float().contiguous()\n",
    "        x += torch.distributions.Uniform(0.0, 0.5).sample(x.shape).to(ptu.device)\n",
    "        loss = model.nll(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "\n",
    "def train_epochs_q2(model, train_loader, test_loader, train_args):\n",
    "    epochs, lr = train_args[\"epochs\"], train_args[\"lr\"]\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    test_loss = eval_loss(model, test_loader)\n",
    "    test_losses.append(test_loss)  # loss at init\n",
    "    for epoch in tqdm_notebook(range(epochs), desc=\"Epoch\", leave=False):\n",
    "        model.train()\n",
    "        epoch_train_losses = train_with_dequantization_q2(\n",
    "            model, train_loader, optimizer\n",
    "        )\n",
    "        train_losses.extend(epoch_train_losses)\n",
    "\n",
    "        test_loss = eval_loss(model, test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1iegeT2v6mi"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "ptu.set_gpu_mode(True)\n",
    "\n",
    "\n",
    "class MaskConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        assert mask_type == \"A\" or mask_type == \"B\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.register_buffer(\"mask\", torch.zeros_like(self.weight))\n",
    "        self.create_mask(mask_type)\n",
    "\n",
    "    def forward(self, input, cond=None):\n",
    "        batch_size = input.shape[0]\n",
    "        out = F.conv2d(\n",
    "            input,\n",
    "            self.weight * self.mask,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            self.padding,\n",
    "            self.dilation,\n",
    "            self.groups,\n",
    "        )\n",
    "        return out\n",
    "\n",
    "    def create_mask(self, mask_type):\n",
    "        k = self.kernel_size[0]\n",
    "        self.mask[:, :, : k // 2] = 1\n",
    "        self.mask[:, :, k // 2, : k // 2] = 1\n",
    "        if mask_type == \"B\":\n",
    "            self.mask[:, :, k // 2, k // 2] = 1\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = nn.ModuleList(\n",
    "            [\n",
    "                nn.ReLU(),\n",
    "                MaskConv2d(\"B\", in_channels, in_channels // 2, 1, **kwargs),\n",
    "                nn.ReLU(),\n",
    "                MaskConv2d(\n",
    "                    \"B\", in_channels // 2, in_channels // 2, 7, padding=3, **kwargs\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                MaskConv2d(\"B\", in_channels // 2, in_channels, 1, **kwargs),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, cond=None):\n",
    "        out = x\n",
    "        for layer in self.block:\n",
    "            if isinstance(layer, MaskConv2d):\n",
    "                out = layer(out, cond=cond)\n",
    "            else:\n",
    "                out = layer(out)\n",
    "        return out + x\n",
    "\n",
    "\n",
    "class LayerNorm(nn.LayerNorm):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x_shape = x.shape\n",
    "        x = super().forward(x)\n",
    "        return x.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "\n",
    "class AutoregressiveFlowPixelCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        n_filters=64,\n",
    "        kernel_size=7,\n",
    "        n_layers=5,\n",
    "        use_resblock=False,\n",
    "        n_components=2,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert n_layers >= 2\n",
    "        n_channels = input_shape[0]\n",
    "\n",
    "        if use_resblock:\n",
    "            block_init = lambda: ResBlock(n_filters, **kwargs)\n",
    "        else:\n",
    "            block_init = lambda: MaskConv2d(\n",
    "                \"B\",\n",
    "                n_filters,\n",
    "                n_filters,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=kernel_size // 2,\n",
    "                **kwargs\n",
    "            )\n",
    "\n",
    "        model = nn.ModuleList(\n",
    "            [\n",
    "                MaskConv2d(\n",
    "                    \"A\",\n",
    "                    n_channels,\n",
    "                    n_filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=kernel_size // 2,\n",
    "                    **kwargs\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        for _ in range(n_layers):\n",
    "            model.append(LayerNorm(n_filters))\n",
    "            model.extend([nn.ReLU(), block_init()])\n",
    "        model.extend([nn.ReLU(), MaskConv2d(\"B\", n_filters, n_filters, 1, **kwargs)])\n",
    "        model.extend(\n",
    "            [\n",
    "                nn.ReLU(),\n",
    "                MaskConv2d(\"B\", n_filters, n_components * 3 * n_channels, 1, **kwargs),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.net = model\n",
    "        self.input_shape = input_shape\n",
    "        self.n_channels = n_channels\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def forward(self, x, cond=None):\n",
    "        batch_size = x.shape[0]\n",
    "        out = x.float()\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, MaskConv2d) or isinstance(layer, ResBlock):\n",
    "                out = layer(out, cond=cond)\n",
    "            else:\n",
    "                out = layer(out)\n",
    "        return out.view(\n",
    "            batch_size, 3 * self.n_components, *self.input_shape\n",
    "        )  # todo: fix this line\n",
    "\n",
    "    def nll(self, x, cond=None):\n",
    "        loc, log_scale, weight_logits = torch.chunk(self.forward(x), 3, dim=1)\n",
    "        weights = F.softmax(\n",
    "            weight_logits, dim=1\n",
    "        )  # .repeat(1, 1, self.n_components, 1, 1)\n",
    "        log_det_jacobian = Normal(loc, log_scale.exp()).log_prob(\n",
    "            x.unsqueeze(1).repeat(1, 1, self.n_components, 1, 1)\n",
    "        )\n",
    "        return -log_det_jacobian.mean()\n",
    "\n",
    "    def sample(self, n, cond=None):\n",
    "        samples = torch.zeros(n, *self.input_shape).cuda()\n",
    "        with torch.no_grad():\n",
    "            for r in range(self.input_shape[1]):\n",
    "                for c in range(self.input_shape[2]):\n",
    "                    for k in range(self.n_channels):\n",
    "                        loc, log_scale, weight_logits = torch.chunk(\n",
    "                            self.forward(samples), 3, dim=1\n",
    "                        )\n",
    "                        loc, log_scale, weight_logits = (\n",
    "                            loc[:, :, k, r, c],\n",
    "                            log_scale[:, :, k, r, c],\n",
    "                            weight_logits[:, :, k, r, c],\n",
    "                        )\n",
    "                        probs = F.softmax(weight_logits, dim=1)\n",
    "                        chosen_centers = torch.multinomial(probs, 1).squeeze(-1)\n",
    "                        samples[:, k, r, c] = torch.normal(\n",
    "                            loc[torch.arange(n), chosen_centers],\n",
    "                            log_scale[torch.arange(n), chosen_centers].exp(),\n",
    "                        )\n",
    "        return samples.permute(0, 2, 3, 1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtFZU2ymB6_t"
   },
   "outputs": [],
   "source": [
    "def q2(train_data, test_data):\n",
    "    \"\"\"\n",
    "    train_data: A (n_train, H, W, 1) uint8 numpy array of binary images with values in {0, 1}\n",
    "    test_data: A (n_test, H, W, 1) uint8 numpy array of binary images with values in {0, 1}\n",
    "    H = W = 20\n",
    "    Note that you should dequantize your train and test data, your dequantized pixels should all lie in [0,1]\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train_losses evaluated every minibatch\n",
    "    - a (# of epochs + 1,) numpy array of test_losses evaluated once at initialization and after each epoch\n",
    "    - a numpy array of size (100, H, W, 1) of samples with values in [0, 1], where [0,0.5] represents a black pixel\n",
    "        and [0.5,1] represents a white pixel. We will show your samples with and without noise.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    train_data = np.transpose(train_data, (0, 3, 1, 2)).astype(np.float32) / 2.0\n",
    "    test_data = np.transpose(test_data, (0, 3, 1, 2)).astype(np.float32) / 2.0\n",
    "    # train_data = train_data + np.random.uniform(high=0.5, size=train_data.shape)\n",
    "    test_data = test_data + np.random.uniform(high=0.5, size=test_data.shape)\n",
    "\n",
    "    H, W = 20, 20\n",
    "    model = AutoregressiveFlowPixelCNN((1, H, W), n_layers=5, n_components=10).cuda()\n",
    "\n",
    "    train_loader = data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "    test_loader = data.DataLoader(test_data, batch_size=128)\n",
    "    train_losses, test_losses = train_epochs_q2(\n",
    "        model, train_loader, test_loader, dict(epochs=20, lr=1e-3)\n",
    "    )\n",
    "    samples = model.sample(100)\n",
    "    return train_losses + np.log(2), test_losses + np.log(2), samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iso12bj4Tup8"
   },
   "source": [
    "### Results\n",
    "\n",
    "Once you've implemented `q2`, execute the cells below to visualize and save your results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874,
     "referenced_widgets": [
      "b7f8f12539b24eca80463184dc54e8fa",
      "d80db0014ee1496ca7314fdce13e6268",
      "a1dd767fadd942b1bc3dd19c377d2315",
      "f27d814af9aa4e7d95fa851f631c4f92",
      "1a125492cfd04b7e87f03386afa6f505",
      "97728b8786e846c8877ddc4ea4a0d514",
      "7c85d556dc984328ba703e6d12e6d3c9",
      "27e5019c33894c819ececf390846eb1c"
     ]
    },
    "colab_type": "code",
    "id": "njfGrZ74Jm2d",
    "outputId": "57517f3c-801e-4676-d0b9-d40ae0664ded"
   },
   "outputs": [],
   "source": [
    "q2_save_results(q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dP8lmmk7Xrct"
   },
   "source": [
    "# Question 3: RealNVP on Higher Dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wnyhDNqcAcw"
   },
   "source": [
    "In this problem, you will train a flow model to invertibly map a high dimensional dataset of celebrity\n",
    "faces to gaussian noise. The dataset is a low-resolution (32 × 32) version of the CelebA-HQ dataset that has been quantized to 2 bits per color channel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "ysoGwlFaftC1",
    "outputId": "25effcab-d19d-452d-95d1-00f6d0c0d8aa"
   },
   "outputs": [],
   "source": [
    "visualize_q3_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iEMfKiqmfzJp"
   },
   "source": [
    "## Part (a): RealNVP [40pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSGU6Mz3ftZe"
   },
   "source": [
    "Use the affine coupling flow from RealNVP and a form of [data-dependent initialization](https://arxiv.org/abs/1602.07868) that normalizes activations from an initial forward pass with a minibatch.\n",
    "We describe a reference architecture below that can achieve good performance, but you are free\n",
    "and encouraged to use different architectures and/or structure your code differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QO6i0oY5CBGh"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "Preprocess() # dequantization, logit trick from RealNVP (Dinh et al) Section 4.1\n",
    "\n",
    "for _ in range(4):\n",
    "  AffineCouplingWithCheckerboard() # Figure 3 in Dinh et al - (left)\n",
    "  ActNorm() # described in Glow (Kingma & Dhariwal) Section 3.1\n",
    "Squeeze(), # [b, c, h, w] --> [b, c*4, h//2, w//2]\n",
    "\n",
    "for _ in range(3):\n",
    "  AffineCouplingWithChannel()\n",
    "  ActNorm()\n",
    "Unsqueeze(), # [b, c*4, h//2, w//2] --> [b, c, h, w]\n",
    "\n",
    "for _ in range(3):\n",
    "  AffineCouplingWithCheckerboard()\n",
    "  ActNorm()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TX1Kyl8EBF45"
   },
   "source": [
    "Here, we provide pseudocode for the basic structure of each coupling layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyCXu1PSrIUb"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# pseudocode\n",
    "ResnetBlock: n_filters\n",
    "  h = x\n",
    "  h = conv2d(n_filters, n_filters, (1,1), stride=1, padding=0)(h)\n",
    "  h = relu(h)\n",
    "  h = conv2d(n_filters, n_filters, (3,3), stride=1, padding=1)(h)\n",
    "  h = relu(h)\n",
    "  h = conv2d(n_filters, n_filters, (1,1), stride=1, padding=0)(h)\n",
    "  return h + x\n",
    "\n",
    "SimpleResnet: n_filters = 256, n_blocks = 8, n_out\n",
    "  conv2d(in_channels, n_filters=128, (3,3), stride=1, padding=1)\n",
    "  apply 8 ResnetBlocks with n_filters=128\n",
    "  relu()\n",
    "  conv2d(n_filters, n_filters=n_out, (3,3), stride=1, padding=1)\n",
    "  \n",
    "AffineCoupling(x, mask):\n",
    "  x_ = x * mask\n",
    "  log_s, t = torch.chunk(SimpleResnet(x_), 2, dim=1)\n",
    "  # todo: calculate log_scale, as done in Q1(b)\n",
    "  t = t * (1.0 - mask)\n",
    "  log_scale = log_scale * (1.0 - mask)\n",
    "  z = x * torch.exp(log_scale) + t\n",
    "  log_det_jacobian = log_scale\n",
    "  return z, log_det_jacobian\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rT4Mi1PlBb5B"
   },
   "source": [
    "We use an Adam Optimizer with a warmup over 200 steps till a learning rate of 5e-4. We didn’t decay the learning rate but it is a generally recommended practice while training generative models. We show samples from our model at the end of training, as well as interpolations between several images in our dataset.  Our reference solution achieves a test loss of about 0.40 bits/dim after 100 epochs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50WsEzhx4Uua"
   },
   "source": [
    "**You will provide these deliverables**\n",
    "\n",
    "\n",
    "1.   Over the course of training, record the average negative log-likelihood (nats / dim) of the training data (per minibatch) and test data (for your entire test set). Code is provided that automatically plots the training curves. \n",
    "2.   Report the final test set performance of your final model\n",
    "3. 100 samples from the final trained model\n",
    "4. 5 rows of interpolations between images in the test set; each row consists of the start and end images, and 4 intermediate ones. You should return 30 total images. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EleefdNuciyc"
   },
   "source": [
    "### Solution\n",
    "Fill out the function below and return the necessary arguments. Feel free to create more cells if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enKe0Q7F4Zfi"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# conv2d with weight normalization...\n",
    "class WeightNormConv2d(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel_size, stride=1, padding=0, bias=True):\n",
    "        super(WeightNormConv2d, self).__init__()\n",
    "        self.conv = nn.utils.weight_norm(\n",
    "            nn.Conv2d(\n",
    "                in_dim, out_dim, kernel_size, stride=stride, padding=padding, bias=bias\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class ActNorm(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(ActNorm, self).__init__()\n",
    "        self.log_scale = nn.Parameter(\n",
    "            torch.zeros(1, n_channels, 1, 1), requires_grad=True\n",
    "        )\n",
    "        self.shift = nn.Parameter(torch.zeros(1, n_channels, 1, 1), requires_grad=True)\n",
    "        self.n_channels = n_channels\n",
    "        self.initialized = False\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        if reverse:\n",
    "            return (x - self.shift) * torch.exp(-self.log_scale), self.log_scale\n",
    "        else:\n",
    "            if not self.initialized:\n",
    "                self.shift.data = -torch.mean(x, dim=[0, 2, 3], keepdim=True)\n",
    "                self.log_scale.data = -torch.log(\n",
    "                    torch.std(\n",
    "                        x.permute(1, 0, 2, 3).reshape(self.n_channels, -1), dim=1\n",
    "                    ).reshape(1, self.n_channels, 1, 1)\n",
    "                )\n",
    "                self.initialized = True\n",
    "                result = x * torch.exp(self.log_scale) + self.shift\n",
    "            return x * torch.exp(self.log_scale) + self.shift, self.log_scale\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            WeightNormConv2d(dim, dim, (1, 1), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            WeightNormConv2d(dim, dim, (3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            WeightNormConv2d(dim, dim, (1, 1), stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class SimpleResnet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=6, n_filters=128, n_blocks=8):\n",
    "        super(SimpleResnet, self).__init__()\n",
    "        layers = [\n",
    "            WeightNormConv2d(in_channels, n_filters, (3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        for _ in range(n_blocks):\n",
    "            layers.append(ResnetBlock(n_filters))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(\n",
    "            WeightNormConv2d(n_filters, out_channels, (3, 3), stride=1, padding=1)\n",
    "        )\n",
    "        self.resnet = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "\n",
    "class AffineCheckerboardTransform(nn.Module):\n",
    "    def __init__(self, type=1.0):\n",
    "        super(AffineCheckerboardTransform, self).__init__()\n",
    "        self.mask = self.build_mask(type=type)\n",
    "        self.scale = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        self.scale_shift = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        self.resnet = SimpleResnet()\n",
    "\n",
    "    def build_mask(self, type=1.0):\n",
    "        # if type == 1.0, the top left corner will be 1.0\n",
    "        # if type == 0.0, the top left corner will be 0.0\n",
    "        mask = np.arange(32).reshape(-1, 1) + np.arange(32)\n",
    "        mask = np.mod(type + mask, 2)\n",
    "        mask = mask.reshape(-1, 1, 32, 32)\n",
    "        return torch.tensor(mask.astype(\"float32\")).to(device)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        # returns transform(x), log_det\n",
    "        batch_size, n_channels, _, _ = x.shape\n",
    "        mask = self.mask.repeat(batch_size, 1, 1, 1)\n",
    "        x_ = x * mask\n",
    "\n",
    "        log_s, t = self.resnet(x_).split(n_channels, dim=1)\n",
    "        log_s = self.scale * torch.tanh(log_s) + self.scale_shift\n",
    "        t = t * (1.0 - mask)\n",
    "        log_s = log_s * (1.0 - mask)\n",
    "\n",
    "        if reverse:  # inverting the transformation\n",
    "            x = (x - t) * torch.exp(-log_s)\n",
    "        else:\n",
    "            x = x * torch.exp(log_s) + t\n",
    "        return x, log_s\n",
    "\n",
    "\n",
    "class AffineChannelTransform(nn.Module):\n",
    "    def __init__(self, modify_top):\n",
    "        super(AffineChannelTransform, self).__init__()\n",
    "        self.modify_top = modify_top\n",
    "        self.scale = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        self.scale_shift = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        self.resnet = SimpleResnet(in_channels=6, out_channels=12)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        n_channels = x.shape[1]\n",
    "        if self.modify_top:\n",
    "            on, off = x.split(n_channels // 2, dim=1)\n",
    "        else:\n",
    "            off, on = x.split(n_channels // 2, dim=1)\n",
    "        log_s, t = self.resnet(off).split(n_channels // 2, dim=1)\n",
    "        log_s = self.scale * torch.tanh(log_s) + self.scale_shift\n",
    "\n",
    "        if reverse:  # inverting the transformation\n",
    "            on = (on - t) * torch.exp(-log_s)\n",
    "        else:\n",
    "            on = on * torch.exp(log_s) + t\n",
    "\n",
    "        if self.modify_top:\n",
    "            return torch.cat([on, off], dim=1), torch.cat(\n",
    "                [log_s, torch.zeros_like(log_s)], dim=1\n",
    "            )\n",
    "        else:\n",
    "            return torch.cat([off, on], dim=1), torch.cat(\n",
    "                [torch.zeros_like(log_s), log_s], dim=1\n",
    "            )\n",
    "\n",
    "\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RealNVP, self).__init__()\n",
    "\n",
    "        self.prior = torch.distributions.Normal(\n",
    "            torch.tensor(0.0).to(device), torch.tensor(1.0).to(device)\n",
    "        )\n",
    "        # self.prior = torch.distributions.Normal(torch.tensor(0.).to(device), torch.tensor(1.).to(device))\n",
    "        self.checker_transforms1 = nn.ModuleList(\n",
    "            [\n",
    "                AffineCheckerboardTransform(1.0),\n",
    "                ActNorm(3),\n",
    "                AffineCheckerboardTransform(0.0),\n",
    "                ActNorm(3),\n",
    "                AffineCheckerboardTransform(1.0),\n",
    "                ActNorm(3),\n",
    "                AffineCheckerboardTransform(0.0),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.channel_transforms = nn.ModuleList(\n",
    "            [\n",
    "                AffineChannelTransform(True),\n",
    "                ActNorm(12),\n",
    "                AffineChannelTransform(False),\n",
    "                ActNorm(12),\n",
    "                AffineChannelTransform(True),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.checker_transforms2 = nn.ModuleList(\n",
    "            [\n",
    "                AffineCheckerboardTransform(1.0),\n",
    "                ActNorm(3),\n",
    "                AffineCheckerboardTransform(0.0),\n",
    "                ActNorm(3),\n",
    "                AffineCheckerboardTransform(1.0),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def squeeze(self, x):\n",
    "        # C x H x W -> 4C x H/2 x W/2\n",
    "        [B, C, H, W] = list(x.size())\n",
    "        x = x.reshape(B, C, H // 2, 2, W // 2, 2)\n",
    "        x = x.permute(0, 1, 3, 5, 2, 4)\n",
    "        x = x.reshape(B, C * 4, H // 2, W // 2)\n",
    "        return x\n",
    "\n",
    "    def undo_squeeze(self, x):\n",
    "        #  4C x H/2 x W/2  ->  C x H x W\n",
    "        [B, C, H, W] = list(x.size())\n",
    "        x = x.reshape(B, C // 4, 2, 2, H, W)\n",
    "        x = x.permute(0, 1, 4, 2, 5, 3)\n",
    "        x = x.reshape(B, C // 4, H * 2, W * 2)\n",
    "        return x\n",
    "\n",
    "    def g(self, z):\n",
    "        # z -> x (inverse of f)\n",
    "        x = z\n",
    "        for op in reversed(self.checker_transforms2):\n",
    "            x, _ = op.forward(x, reverse=True)\n",
    "        x = self.squeeze(x)\n",
    "        for op in reversed(self.channel_transforms):\n",
    "            x, _ = op.forward(x, reverse=True)\n",
    "        x = self.undo_squeeze(x)\n",
    "        for op in reversed(self.checker_transforms1):\n",
    "            x, _ = op.forward(x, reverse=True)\n",
    "        return x\n",
    "\n",
    "    def f(self, x):\n",
    "        # maps x -> z, and returns the log determinant (not reduced)\n",
    "        z, log_det = x, torch.zeros_like(x)\n",
    "        for op in self.checker_transforms1:\n",
    "            z, delta_log_det = op.forward(z)\n",
    "            log_det += delta_log_det\n",
    "        z, log_det = self.squeeze(z), self.squeeze(log_det)\n",
    "        for op in self.channel_transforms:\n",
    "            z, delta_log_det = op.forward(z)\n",
    "            log_det += delta_log_det\n",
    "        z, log_det = self.undo_squeeze(z), self.undo_squeeze(log_det)\n",
    "        for op in self.checker_transforms2:\n",
    "            z, delta_log_det = op.forward(z)\n",
    "            log_det += delta_log_det\n",
    "        return z, log_det\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        z, log_det = self.f(x)\n",
    "        return torch.sum(log_det, [1, 2, 3]) + torch.sum(\n",
    "            self.prior.log_prob(z), [1, 2, 3]\n",
    "        )\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        z = self.prior.sample([num_samples, 3, 32, 32])\n",
    "        return self.g(z)\n",
    "\n",
    "\n",
    "class Solver(object):\n",
    "    def __init__(self, learning_rate=5e-4, n_epochs=128):\n",
    "        self.train_loader, self.val_loader = self.create_loaders()\n",
    "        self.log_interval = 100\n",
    "        self.n_epochs = n_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_batches_in_epoch = len(self.train_loader)\n",
    "\n",
    "    def build(self):\n",
    "        self.flow = RealNVP().to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.flow.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def create_loaders(self):\n",
    "        train, test = get_q3_data()\n",
    "        train = np.transpose(train, axes=[0, 3, 1, 2])  # NCHW 20000 x 3 x 32 x 32\n",
    "        test = np.transpose(test, axes=[0, 3, 1, 2])  # NCHW 6838 x 3 x 32 x 32\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train, batch_size=64, shuffle=False, pin_memory=False\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test, batch_size=64, shuffle=False, pin_memory=False\n",
    "        )\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    def preprocess(self, x, reverse=False, dequantize=True):\n",
    "        if reverse:  # doesn't map back to [0, 4]\n",
    "            x = 1.0 / (1 + torch.exp(-x))\n",
    "            x -= 0.05\n",
    "            x /= 0.9\n",
    "            return x\n",
    "        else:\n",
    "            # dequantization\n",
    "            if dequantize:\n",
    "                x += torch.distributions.Uniform(0.0, 1.0).sample(x.shape).to(device)\n",
    "            x /= 4.0\n",
    "\n",
    "            # logit operation\n",
    "            x *= 0.9\n",
    "            x += 0.05\n",
    "            logit = torch.log(x) - torch.log(1.0 - x)\n",
    "            log_det = (\n",
    "                torch.nn.functional.softplus(logit)\n",
    "                + torch.nn.functional.softplus(-logit)\n",
    "                + torch.log(torch.tensor(0.9))\n",
    "                - torch.log(torch.tensor(4.0))\n",
    "            )\n",
    "            return logit, torch.sum(log_det, dim=(1, 2, 3))\n",
    "\n",
    "    def train(self):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for epoch_i in range(self.n_epochs):\n",
    "            epoch_i += 1\n",
    "\n",
    "            self.flow.train()\n",
    "            self.batch_loss_history = []\n",
    "\n",
    "            for batch_i, image in enumerate(\n",
    "                tqdm_notebook(self.train_loader, desc=\"Batch\", leave=False)\n",
    "            ):\n",
    "\n",
    "                batch_i += 1\n",
    "                # [batch_size, 3, 32, 32]\n",
    "                image = Variable(image).to(device)\n",
    "                logit_x, log_det = self.preprocess(image.float())\n",
    "                log_prob = self.flow.log_prob(logit_x)\n",
    "                log_prob += log_det\n",
    "\n",
    "                batch_loss = -torch.mean(log_prob) / (3.0 * 32.0 * 32.0)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                batch_loss = float(batch_loss.data)\n",
    "                self.batch_loss_history.append(batch_loss)\n",
    "\n",
    "            epoch_loss = np.mean(self.batch_loss_history)\n",
    "            tqdm.write(f\"Epoch {epoch_i} Loss: {epoch_loss:.2f}\")\n",
    "\n",
    "            if epoch_i % 10 == 0:\n",
    "                self.save_model(\"realnvp{}.model\".format(str(epoch_i)))\n",
    "            train_losses.append(epoch_loss)\n",
    "            val_losses.append(self.get_loss(self.val_loader))\n",
    "            np.save(\"train_losses.npy\", np.array(train_losses))\n",
    "            np.save(\"val_losses.npy\", np.array(val_losses))\n",
    "\n",
    "        self.save_model(\"realnvp_final.model\")\n",
    "        return train_losses, val_losses\n",
    "\n",
    "    def get_loss(self, loader):\n",
    "        \"\"\"Compute error on provided data set\"\"\"\n",
    "        errors = []\n",
    "        # cuda.synchronize()\n",
    "        start = time.time()\n",
    "\n",
    "        self.flow.eval()\n",
    "\n",
    "        for image in loader:\n",
    "            with torch.no_grad():\n",
    "                image = image.to(device)\n",
    "                logit_x, log_det = self.preprocess(image.float())\n",
    "                log_prob = self.flow.log_prob(logit_x)\n",
    "                log_prob += log_det\n",
    "\n",
    "                loss = -torch.mean(log_prob) / (3.0 * 32.0 * 32.0)\n",
    "                error = float(loss.data)\n",
    "                errors.append(error)\n",
    "\n",
    "        # cuda.synchronize()\n",
    "        time_test = time.time() - start\n",
    "        log_string = f\"Calc done! | It took {time_test:.1f}s | \"\n",
    "        log_string += f\"Loss: {np.mean(errors):.2f}\"\n",
    "        tqdm.write(log_string)\n",
    "        return np.mean(errors)\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        with torch.no_grad():\n",
    "            raw_samples = self.flow.sample(num_samples).cpu()\n",
    "            samples = self.preprocess(raw_samples, reverse=True)\n",
    "            return samples.cpu().numpy()\n",
    "\n",
    "    def interpolate(self):\n",
    "        self.flow.eval()\n",
    "        good = [5, 13, 16, 19, 22]\n",
    "        indices = []\n",
    "        for index in good:\n",
    "            indices.append(index * 2)\n",
    "            indices.append(index * 2 + 1)\n",
    "        with torch.no_grad():\n",
    "            actual_images = next(iter(self.val_loader))[indices].to(\"cpu\")\n",
    "            assert actual_images.shape[0] % 2 == 0\n",
    "            logit_actual_images, _ = self.preprocess(\n",
    "                actual_images.float(), dequantize=False\n",
    "            )\n",
    "            latent_images, _ = self.flow.f(logit_actual_images)\n",
    "            latents = []\n",
    "            for i in range(0, actual_images.shape[0], 2):\n",
    "                a = latent_images[i : i + 1]\n",
    "                b = latent_images[i + 1 : i + 2]\n",
    "                diff = (b - a) / 5.0\n",
    "                latents.append(a)\n",
    "                for j in range(1, 5):\n",
    "                    latents.append(a + diff * float(j))\n",
    "                latents.append(b)\n",
    "            latents = torch.cat(latents, dim=0)\n",
    "            logit_results = self.flow.g(latents)\n",
    "            results = self.preprocess(logit_results, reverse=True)\n",
    "            return results.cpu().numpy()\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        torch.save(self.flow, filename)\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        self.flow = torch.load(filename, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWualafa-tpD"
   },
   "outputs": [],
   "source": [
    "def q3_a(train_data, test_data):\n",
    "    \"\"\"\n",
    "    train_data: A (n_train, H, W, 3) uint8 numpy array of quantized images with values in {0, 1, 2, 3}\n",
    "    test_data: A (n_test, H, W, 3) uint8 numpy array of binary images with values in {0, 1, 2, 3}\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train_losses evaluated every minibatch\n",
    "    - a (# of epochs + 1,) numpy array of test_losses evaluated once at initialization and after each epoch\n",
    "    - a numpy array of size (100, H, W, 3) of samples with values in [0, 1]\n",
    "    - a numpy array of size (30, H, W, 3) of interpolations with values in [0, 1].\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    solver = Solver(n_epochs=1)\n",
    "    solver.build()\n",
    "    solver.load_model(\"realnvp_final.model\")\n",
    "    train_losses = np.load(\"train_losses.npy\")\n",
    "    test_losses = np.load(\"val_losses.npy\")\n",
    "    samples = np.transpose(solver.sample(100), axes=[0, 2, 3, 1])\n",
    "    interpolations = np.transpose(solver.interpolate(), axes=[0, 2, 3, 1])\n",
    "    return train_losses, test_losses, samples, interpolations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0EPVfz1cpq0"
   },
   "source": [
    "### Results\n",
    "\n",
    "Once you've implemented `q3_a`, execute the cells below to visualize and save your results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zL6GoOoRu-F0"
   },
   "outputs": [],
   "source": [
    "solver = Solver(n_epochs=100)\n",
    "solver.build()\n",
    "train, val = solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "colab_type": "code",
    "id": "xNxXqVZpAd_V",
    "outputId": "10757f68-f08d-4e2b-80f7-dfbe54d4e2e2"
   },
   "outputs": [],
   "source": [
    "q3_save_results(q3_a, \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Hi51jz3f50m"
   },
   "source": [
    "## Part (b): Exploring bad masking schemes [10pt]\n",
    "\n",
    "As shown in lecture, the choice of masking or partitioning scheme affects the quality of the final flow model. In this part, design a *bad* masking scheme and train a model with it on the same CelebA dataset. \n",
    "\n",
    "**Provide the same deliverables as part (a)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahkg1ZWJrntP"
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kiAwoUUlNYoC"
   },
   "outputs": [],
   "source": [
    "class AffineHalfHalfTransform(nn.Module):\n",
    "    def __init__(self, type):\n",
    "        super(AffineHalfHalfTransform, self).__init__()\n",
    "        self.mask = self.build_mask(type=type)\n",
    "        self.scale = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        self.scale_shift = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        self.resnet = SimpleResnet()\n",
    "\n",
    "    def build_mask(self, type):\n",
    "        # if type == \"top\", the top half is 1s\n",
    "        # if type == \"bottom\", the bottom half is 1s\n",
    "        # if type == \"left\", left half is 1s\n",
    "        # if type == right\", right half is 1s\n",
    "        assert type in {\"top\", \"bottom\", \"left\", \"right\"}\n",
    "        if type == \"bottom\":\n",
    "            mask = np.concatenate(\n",
    "                [np.zeros([1, 1, 16, 32]), np.ones([1, 1, 16, 32])], axis=2\n",
    "            )\n",
    "        elif type == \"top\":\n",
    "            mask = np.concatenate(\n",
    "                [np.ones([1, 1, 16, 32]), np.zeros([1, 1, 16, 32])], axis=2\n",
    "            )\n",
    "        elif type == \"left\":\n",
    "            mask = np.concatenate(\n",
    "                [np.ones([1, 1, 32, 16]), np.zeros([1, 1, 32, 16])], axis=3\n",
    "            )\n",
    "        elif type == \"right\":\n",
    "            mask = np.concatenate(\n",
    "                [np.zeros([1, 1, 32, 16]), np.ones([1, 1, 32, 16])], axis=3\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return torch.tensor(mask.astype(\"float32\")).to(device)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        # returns transform(x), log_det\n",
    "        batch_size, n_channels, _, _ = x.shape\n",
    "        mask = self.mask.repeat(batch_size, 1, 1, 1)\n",
    "        x_ = x * mask\n",
    "\n",
    "        log_s, t = self.resnet(x_).split(n_channels, dim=1)\n",
    "        log_s = self.scale * torch.tanh(log_s) + self.scale_shift\n",
    "        t = t * (1.0 - mask)\n",
    "        log_s = log_s * (1.0 - mask)\n",
    "\n",
    "        if reverse:  # inverting the transformation\n",
    "            x = (x - t) * torch.exp(-log_s)\n",
    "        else:\n",
    "            x = x * torch.exp(log_s) + t\n",
    "        return x, log_s\n",
    "\n",
    "\n",
    "class BadRealNVP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BadRealNVP, self).__init__()\n",
    "\n",
    "        self.prior = torch.distributions.Normal(\n",
    "            torch.tensor(0.0).to(device), torch.tensor(1.0).to(device)\n",
    "        )\n",
    "        self.transforms = nn.ModuleList(\n",
    "            [\n",
    "                AffineHalfHalfTransform(\"top\"),\n",
    "                ActNorm(3),\n",
    "                AffineHalfHalfTransform(\"bottom\"),\n",
    "                ActNorm(3),\n",
    "                AffineHalfHalfTransform(\"left\"),\n",
    "                ActNorm(3),\n",
    "                AffineHalfHalfTransform(\"right\"),\n",
    "                ActNorm(3),\n",
    "                AffineHalfHalfTransform(\"top\"),\n",
    "                ActNorm(3),\n",
    "                AffineHalfHalfTransform(\"bottom\"),\n",
    "                ActNorm(3),\n",
    "                AffineHalfHalfTransform(\"left\"),\n",
    "                ActNorm(3),\n",
    "                AffineHalfHalfTransform(\"right\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def g(self, z):\n",
    "        # z -> x (inverse of f)\n",
    "        x = z\n",
    "        for op in reversed(self.transforms):\n",
    "            x, _ = op.forward(x, reverse=True)\n",
    "        return x\n",
    "\n",
    "    def f(self, x):\n",
    "        # maps x -> z, and returns the log determinant (not reduced)\n",
    "        z, log_det = x, torch.zeros_like(x)\n",
    "        for op in self.transforms:\n",
    "            z, delta_log_det = op.forward(z)\n",
    "            log_det += delta_log_det\n",
    "        return z, log_det\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        z, log_det = self.f(x)\n",
    "        return torch.sum(log_det, [1, 2, 3]) + torch.sum(\n",
    "            self.prior.log_prob(z), [1, 2, 3]\n",
    "        )\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        z = self.prior.sample([num_samples, 3, 32, 32])\n",
    "        return self.g(z)\n",
    "\n",
    "\n",
    "class BadSolver(Solver):\n",
    "    def __init__(self, learning_rate=5e-4, n_epochs=128):\n",
    "        super(BadSolver, self).__init__(learning_rate, n_epochs)\n",
    "\n",
    "    def build(self):\n",
    "        self.flow = BadRealNVP().to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.flow.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def train(self):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for epoch_i in range(self.n_epochs):\n",
    "            epoch_i += 1\n",
    "\n",
    "            self.flow.train()\n",
    "            self.batch_loss_history = []\n",
    "\n",
    "            for batch_i, image in enumerate(\n",
    "                tqdm_notebook(self.train_loader, desc=\"Batch\", leave=False)\n",
    "            ):\n",
    "\n",
    "                batch_i += 1\n",
    "                # [batch_size, 3, 32, 32]\n",
    "                image = Variable(image).to(device)\n",
    "                logit_x, log_det = self.preprocess(image.float())\n",
    "                log_prob = self.flow.log_prob(logit_x)\n",
    "                log_prob += log_det\n",
    "\n",
    "                batch_loss = -torch.mean(log_prob) / (3.0 * 32.0 * 32.0)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                batch_loss = float(batch_loss.data)\n",
    "                self.batch_loss_history.append(batch_loss)\n",
    "\n",
    "            epoch_loss = np.mean(self.batch_loss_history)\n",
    "            tqdm.write(f\"Epoch {epoch_i} Loss: {epoch_loss:.2f}\")\n",
    "\n",
    "            if epoch_i % 10 == 0:\n",
    "                self.save_model(\"badrealnvp{}.model\".format(str(epoch_i)))\n",
    "            train_losses.append(epoch_loss)\n",
    "            val_losses.append(self.get_loss(self.val_loader))\n",
    "            np.save(\"bad_train_losses.npy\", np.array(train_losses))\n",
    "            np.save(\"bad_val_losses.npy\", np.array(val_losses))\n",
    "\n",
    "        self.save_model(\"badrealnvp_final.model\")\n",
    "        np.save(\"bad_train_losses.npy\", np.array(train_losses))\n",
    "        np.save(\"bad_val_losses.npy\", np.array(val_losses))\n",
    "        return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Pw-8auZf6oE"
   },
   "outputs": [],
   "source": [
    "def q3_b(train_data, test_data):\n",
    "    \"\"\"\n",
    "    train_data: A (n_train, H, W, 3) uint8 numpy array of quantized images with values in {0, 1, 2, 3}\n",
    "    test_data: A (n_test, H, W, 3) uint8 numpy array of binary images with values in {0, 1, 2, 3}\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train_losses evaluated every minibatch\n",
    "    - a (# of epochs + 1,) numpy array of test_losses evaluated once at initialization and after each epoch\n",
    "    - a numpy array of size (100, 3, H, W) of samples with values in [0, 1]\n",
    "    - a numpy array of size (30, 3, H, W) of interpolations with values in [0, 1].\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    solver = BadSolver(n_epochs=1)\n",
    "    solver.build()\n",
    "    solver.load_model(\"badrealnvp_final.model\")\n",
    "    train_losses = np.load(\"bad_train_losses.npy\")\n",
    "    test_losses = np.load(\"bad_val_losses.npy\")\n",
    "    samples = np.transpose(solver.sample(100), axes=[0, 2, 3, 1])\n",
    "    interpolations = np.transpose(solver.interpolate(), axes=[0, 2, 3, 1])\n",
    "    return train_losses, test_losses, samples, interpolations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yr3okDIPrxFO"
   },
   "source": [
    "### Results\n",
    "\n",
    "Once you've implemented `q3_b`, execute the cells below to visualize and save your results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGl2qcE1vB3x"
   },
   "outputs": [],
   "source": [
    "solver = BadSolver(n_epochs=100)\n",
    "solver.build()\n",
    "train, val = solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "colab_type": "code",
    "id": "DGYtb_1Tf6nA",
    "outputId": "36f5c7c7-ebf6-4282-caca-1c1db934a23c"
   },
   "outputs": [],
   "source": [
    "q3_save_results(q3_b, \"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMZLcaHwLNNL"
   },
   "source": [
    "# Question 4: Bonus Questions (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PEI31Zh0PE9g"
   },
   "source": [
    "## Q4(a): Multiscale RealNVP [10pt]\n",
    "Following the alternating checkerboard, channel squeeze, and channel partition scheme used in https://arxiv.org/abs/1605.08803, learn a multiscale RealNVP model on our CelebA dataset used in Question 3. We expect the same deliverables as in Question 3; additionally, make sure to include analysis on any difference in qualitative or quantitative differences you see in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jboOas0xXYjG"
   },
   "outputs": [],
   "source": [
    "def q4_a(train_data, test_data):\n",
    "    \"\"\"\n",
    "    train_data: A (n_train, H, W, 3) uint8 numpy array of quantized images with values in {0, 1, 2, 3}\n",
    "    test_data: A (n_test, H, W, 3) uint8 numpy array of binary images with values in {0, 1, 2, 3}\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train_losses evaluated every minibatch\n",
    "    - a (# of epochs + 1,) numpy array of test_losses evaluated once at initialization and after each epoch\n",
    "    - a numpy array of size (100, 3, H, W) of samples with values in [0, 1]\n",
    "    - a numpy array of size (30, 3, H, W) of interpolations with values in [0, 1].\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8zWH_SnPwcN"
   },
   "outputs": [],
   "source": [
    "q3_save_results(q4_a, \"bonus_a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0oMGXWMzP4oO"
   },
   "source": [
    "## Q4(b): Glow [5pt]\n",
    "The Glow paper introduces the invertible 1x1 convolution as a replacement for the permutation scheme that follows the channel squeezing step. Use this in your model from Question 3, and report the same deliverables. Make sure to include analysis on any difference in qualitative or quantitative differences you see in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-qpWL8XXawq"
   },
   "outputs": [],
   "source": [
    "def q4_b(train_data, test_data):\n",
    "    \"\"\"\n",
    "    train_data: A (n_train, H, W, 3) uint8 numpy array of quantized images with values in {0, 1, 2, 3}\n",
    "    test_data: A (n_test, H, W, 3) uint8 numpy array of binary images with values in {0, 1, 2, 3}\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train_losses evaluated every minibatch\n",
    "    - a (# of epochs + 1,) numpy array of test_losses evaluated once at initialization and after each epoch\n",
    "    - a numpy array of size (100, 3, H, W) of samples with values in [0, 1]\n",
    "    - a numpy array of size (30, 3, H, W) of interpolations with values in [0, 1].\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbGUrt3NQPWk"
   },
   "outputs": [],
   "source": [
    "q3_save_results(q4_b, \"bonus_b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QF0RJz4nVVp8"
   },
   "source": [
    "# File Saving Utility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfg8RZ01L8h8"
   },
   "outputs": [],
   "source": [
    "# one way to save files\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "for fname in os.listdir(\"results\"):\n",
    "    files.download(\"results/\" + fname)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw2_solutions.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04b5e9c4be5841139ddfcb10a7b0d4d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11be4368f59f4d279ccd6c7e1c3fb975": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14e9adb89a4241a59b73969994ba8287": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15f9f7bea21447a587cbe113bd8f1db8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af99978dfe194c5cabc7a22566a73f32",
      "placeholder": "​",
      "style": "IPY_MODEL_925588a883d24a239f2dce621f3c3474",
      "value": "100% 250/250 [00:38&lt;00:00,  6.52it/s]"
     }
    },
    "1a125492cfd04b7e87f03386afa6f505": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "26279b5b00d249d08db193c5d458d788": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27e5019c33894c819ececf390846eb1c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b5760ae26d546fe995e5adce3adfac8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ff11b35ae2445d48f3eb9f38e98d2de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4305a379952c403c831aa80a7277a8c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Epoch",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ff11b35ae2445d48f3eb9f38e98d2de",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72da61b014334c63b49e1704ccb447ab",
      "value": 99
     }
    },
    "4757025924a242268916ec5a7018047d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Epoch",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ad5177faa894bf6902daa3274d11007",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a648738a4ba45b5965a917fe4beab92",
      "value": 99
     }
    },
    "47fe7daee7eb41ec82d490f989ab916d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a5f8210c0314f6a924f3fbb1f816a47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4f47243631654ab8b874f69b70581f14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11be4368f59f4d279ccd6c7e1c3fb975",
      "placeholder": "​",
      "style": "IPY_MODEL_b07b523f96de451fb7dc582b43dadef6",
      "value": "100% 250/250 [00:38&lt;00:00,  6.44it/s]"
     }
    },
    "529698ae7efc4f099d9909f4d3f37a79": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64dd75b1a2bf4b329dae8ded5705fcde": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b5760ae26d546fe995e5adce3adfac8",
      "placeholder": "​",
      "style": "IPY_MODEL_14e9adb89a4241a59b73969994ba8287",
      "value": " 99% 99/100 [00:08&lt;00:00, 11.43it/s]"
     }
    },
    "698eb0108e154b799b0bc85f12215c54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d83151bc7c540e1824cfaf1079c2649",
       "IPY_MODEL_15f9f7bea21447a587cbe113bd8f1db8"
      ],
      "layout": "IPY_MODEL_e43bfafcb08344a89b3c4bbc1e4c1045"
     }
    },
    "6bbfc6f0221b4216ba7b79e84d330f1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Epoch",
      "description_tooltip": null,
      "layout": "IPY_MODEL_529698ae7efc4f099d9909f4d3f37a79",
      "max": 250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f8e58fa58b74581a4131dadcef8848f",
      "value": 250
     }
    },
    "6cbb0ecbf2534e808d11b8b73f4381dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72da61b014334c63b49e1704ccb447ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7a7a1e7d8184498cbeba151e810b063d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4757025924a242268916ec5a7018047d",
       "IPY_MODEL_c5835b4964d14f1dbfdf3cdd9f60d494"
      ],
      "layout": "IPY_MODEL_6cbb0ecbf2534e808d11b8b73f4381dc"
     }
    },
    "7c85d556dc984328ba703e6d12e6d3c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f8e58fa58b74581a4131dadcef8848f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "82e1d23df2c34fc98d1b9a276ee435db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4305a379952c403c831aa80a7277a8c2",
       "IPY_MODEL_64dd75b1a2bf4b329dae8ded5705fcde"
      ],
      "layout": "IPY_MODEL_04b5e9c4be5841139ddfcb10a7b0d4d5"
     }
    },
    "8942e1f4d98b4c9385c19d450958e4e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a648738a4ba45b5965a917fe4beab92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8ad5177faa894bf6902daa3274d11007": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d83151bc7c540e1824cfaf1079c2649": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Epoch",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26279b5b00d249d08db193c5d458d788",
      "max": 250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a5f8210c0314f6a924f3fbb1f816a47",
      "value": 250
     }
    },
    "925588a883d24a239f2dce621f3c3474": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97728b8786e846c8877ddc4ea4a0d514": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1dd767fadd942b1bc3dd19c377d2315": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Epoch",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97728b8786e846c8877ddc4ea4a0d514",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a125492cfd04b7e87f03386afa6f505",
      "value": 20
     }
    },
    "af99978dfe194c5cabc7a22566a73f32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b07b523f96de451fb7dc582b43dadef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7f8f12539b24eca80463184dc54e8fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1dd767fadd942b1bc3dd19c377d2315",
       "IPY_MODEL_f27d814af9aa4e7d95fa851f631c4f92"
      ],
      "layout": "IPY_MODEL_d80db0014ee1496ca7314fdce13e6268"
     }
    },
    "c5835b4964d14f1dbfdf3cdd9f60d494": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8942e1f4d98b4c9385c19d450958e4e8",
      "placeholder": "​",
      "style": "IPY_MODEL_d4ae5b64ad24438eb6444532de970923",
      "value": " 99% 99/100 [00:08&lt;00:00, 11.51it/s]"
     }
    },
    "d4ae5b64ad24438eb6444532de970923": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d80db0014ee1496ca7314fdce13e6268": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1dc0632bd95445a8944cd76afb3f668": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bbfc6f0221b4216ba7b79e84d330f1e",
       "IPY_MODEL_4f47243631654ab8b874f69b70581f14"
      ],
      "layout": "IPY_MODEL_47fe7daee7eb41ec82d490f989ab916d"
     }
    },
    "e43bfafcb08344a89b3c4bbc1e4c1045": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f27d814af9aa4e7d95fa851f631c4f92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27e5019c33894c819ececf390846eb1c",
      "placeholder": "​",
      "style": "IPY_MODEL_7c85d556dc984328ba703e6d12e6d3c9",
      "value": "100% 20/20 [02:17&lt;00:00,  6.91s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
